## Course material
* The basics are based on this freely available [book](https://web.stanford.edu/~hastie/Papers/ESLII.pdf) by Hastie, Tibshirani, and Friedman. I also recommend [Murphy's recent book](https://mitpress.mit.edu/books/machine-learning-0).
* For practical illustrations, I rely a lot on @jakevdp's [scikit-learn tutorial](https://github.com/jakevdp/sklearn_scipy2013
).
* The notebooks on Gaussian and Dirichlet processes are [here](https://github.com/rbardenet/bnp-course).
* The Bayesian optimization pacakges for hyperparameter optimization are [hyperopt](https://github.com/hyperopt/hyperopt) and [spearmint](https://github.com/HIPS/Spearmint).
* For more details about comparing classifiers on one or multiple datasets, I recommend [this JMLR paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.141.3142&rep=rep1&type=pdf). In particular, read Section 2.1 for a quick review and some pointers on what to (not) do when using cross-validation.

## TNE instructions
Download the `TNE` directory, cd to `TNE/Code`, and run
`jupyter notebook startingKit.ipynb`
to see what the practical is about. Read and execute all cells to get started. There are questions in the text and exercises at the end of the notebook.

## Kaggle competition
The game is on, check your emails for the relevant links.
